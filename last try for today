import argparse
import sys
import time
import RPi.GPIO as GPIO
import numpy as np
import cv2
from picamera2 import CompletedRequest, MappedArray, Picamera2
from picamera2.devices import IMX500
from picamera2.devices.imx500 import NetworkIntrinsics
from picamera2.devices.imx500.postprocess import softmax

# GPIO pin setup for the traffic light
RED_LIGHT = 17
YELLOW_LIGHT = 27
GREEN_LIGHT = 22

# Initialize the GPIO
GPIO.setmode(GPIO.BCM)
GPIO.setup(RED_LIGHT, GPIO.OUT)
GPIO.setup(YELLOW_LIGHT, GPIO.OUT)
GPIO.setup(GREEN_LIGHT, GPIO.OUT)

# Default to red light on startup
GPIO.output(RED_LIGHT, GPIO.HIGH)
GPIO.output(YELLOW_LIGHT, GPIO.LOW)
GPIO.output(GREEN_LIGHT, GPIO.LOW)

def set_traffic_light(color):
    """Control the traffic light color based on input"""
    print(f"DEBUG: Setting traffic light to: {color}")  # Debugging line
    GPIO.output(RED_LIGHT, GPIO.LOW)
    GPIO.output(YELLOW_LIGHT, GPIO.LOW)
    GPIO.output(GREEN_LIGHT, GPIO.LOW)

    if color == "red":
        GPIO.output(RED_LIGHT, GPIO.HIGH)
    elif color == "yellow":
        GPIO.output(YELLOW_LIGHT, GPIO.HIGH)
    elif color == "green":
        GPIO.output(GREEN_LIGHT, GPIO.HIGH)

def turn_green_light():
    """Turn the traffic light green for 5 seconds, then yellow, and then red"""
    print("ğŸš¦ Turning green light ON!")
    set_traffic_light("green")
    time.sleep(5)  # Green light on for 5 seconds

    print("ğŸŸ¡ Switching to yellow light!")
    set_traffic_light("yellow")
    time.sleep(2)  # Yellow light on for 2 seconds

    print("ğŸ”´ Switching back to red light!")
    set_traffic_light("red")

last_detections = []
LABELS = None

class Classification:
    def __init__(self, idx: int, score: float):
        """Create a Classification object, recording the idx and score."""
        self.idx = idx
        self.score = score

def get_label(request: CompletedRequest, idx: int) -> str:
    """Retrieve the label corresponding to the classification index."""
    global LABELS
    if LABELS is None:
        LABELS = intrinsics.labels
        assert len(LABELS) in [1000, 1001], "Labels file should contain 1000 or 1001 labels."
        output_tensor_size = imx500.get_output_shapes(request.get_metadata())[0][0]
        if output_tensor_size == 1000:
            LABELS = LABELS[1:]  # Ignore the background label if present
    return LABELS[idx]

def parse_and_draw_classification_results(request: CompletedRequest):
    """Parse and draw the classification results in the output tensor."""
    results = parse_classification_results(request)
    draw_classification_results(request, results)

def parse_classification_results(request: CompletedRequest) -> list:
    """Parse the output tensor into the classification results above the threshold."""
    global last_detections
    np_outputs = imx500.get_outputs(request.get_metadata())
    if np_outputs is None:
        return last_detections
    np_output = np_outputs[0]
    if intrinsics.softmax:
        np_output = softmax(np_output)
    top_indices = np.argpartition(-np_output, 3)[:3]  # Get top 3 indices with the highest scores
    top_indices = top_indices[np.argsort(-np_output[top_indices])]  # Sort the top 3 indices by their scores
    last_detections = [Classification(index, np_output[index]) for index in top_indices]
    return last_detections

def draw_classification_results(request: CompletedRequest, results: list, stream: str = "main"):
    """Draw the classification results for this request onto the ISP output."""
    with MappedArray(request, stream) as m:
        if intrinsics.preserve_aspect_ratio:
            b_x, b_y, b_w, b_h = imx500.get_roi_scaled(request)
            color = (255, 0, 0)  # Red for ROI
            cv2.putText(m.array, "ROI", (b_x + 5, b_y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            cv2.rectangle(m.array, (b_x, b_y), (b_x + b_w, b_y + b_h), (255, 0, 0, 0))
            text_left, text_top = b_x, b_y + 20
        else:
            text_left, text_top = 0, 0
        for index, result in enumerate(results):
            label = get_label(request, idx=result.idx)
            text = f"{label}: {result.score:.3f}"

            # Calculate text size and position
            (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            text_x = text_left + 5
            text_y = text_top + 15 + index * 20

            # Create a copy of the array to draw the background with opacity
            overlay = m.array.copy()
            cv2.rectangle(overlay, (text_x, text_y - text_height), (text_x + text_width, text_y + baseline),
                          (255, 255, 255), cv2.FILLED)
            alpha = 0.3
            cv2.addWeighted(overlay, alpha, m.array, 1 - alpha, 0, m.array)

            # Draw text on top of the background
            cv2.putText(m.array, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

def get_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, help="Path of the model",
                        default="/usr/share/imx500-models/imx500_network_mobilenet_v2.rpk")
    parser.add_argument("--fps", type=int, help="Frames per second")
    parser.add_argument("-s", "--softmax", action=argparse.BooleanOptionalAction, help="Add post-process softmax")
    parser.add_argument("-r", "--preserve-aspect-ratio", action=argparse.BooleanOptionalAction,
                        help="Preprocess the image with preserve aspect ratio")
    parser.add_argument("--labels", type=str, help="Path to the labels file")
    parser.add_argument("--print-intrinsics", action="store_true", help="Print JSON network_intrinsics then exit")
    return parser.parse_args()

if __name__ == "__main__":
    args = get_args()

    # This must be called before instantiation of Picamera2
    imx500 = IMX500(args.model)
    intrinsics = imx500.network_intrinsics
    if not intrinsics:
        intrinsics = NetworkIntrinsics()
        intrinsics.task = "classification"
    elif intrinsics.task != "classification":
        print("Network is not a classification task", file=sys.stderr)
        exit()

    # Override intrinsics from args
    for key, value in vars(args).items():
        if key == 'labels' and value is not None:
            with open(value, 'r') as f:
                intrinsics.labels = f.read().splitlines()
        elif hasattr(intrinsics, key) and value is not None:
            setattr(intrinsics, key, value)

    # Defaults
    if intrinsics.labels is None:
        with open("assets/imagenet_labels.txt", "r") as f:
            intrinsics.labels = f.read().splitlines()
    intrinsics.update_with_defaults()

    if args.print_intrinsics:
        print(intrinsics)
        exit()

    picam2 = Picamera2(imx500.camera_num)
    config = picam2.create_preview_configuration(controls={"FrameRate": intrinsics.inference_rate}, buffer_count=12)

    imx500.show_network_fw_progress_bar()
    picam2.start(config, show_preview=True)
    if intrinsics.preserve_aspect_ratio:
        imx500.set_auto_aspect_ratio()

    last_results = None
    picam2.pre_callback = parse_and_draw_classification_results

    while True:
        last_results = parse_classification_results(picam2.capture_metadata())

        # Check if ambulance is detected
        for detection in last_results:
            label = get_label(picam2, detection.idx)
            print(f"DEBUG: Detected {label} with score: {detection.score}")

            if "ambulance" in label.lower() and detection.score > 0.5:  # Adjust threshold as needed
                print("ğŸš‘ Ambulance detected! Turning green light ON.")
                turn_green_light()
            else:
                print("ğŸš« No ambulance detected.")
